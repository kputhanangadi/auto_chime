{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from object_detection.ipynb\n",
      "TensorFlow 2.13.0\n"
     ]
    }
   ],
   "source": [
    "import collections # Handles specialized container datatypes\n",
    "import cv2 # Computer vision library\n",
    "import matplotlib.pyplot as plt # Plotting library\n",
    "import numpy as np # Scientific computing library\n",
    "import import_ipynb\n",
    "import object_detection # Custom object detection program\n",
    "import sys\n",
    "import tensorflow as tf # Machine learning library\n",
    "from tensorflow import keras # Library for neural networks\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "sys.path.append('../')\n",
    "\n",
    " # Show the version of TensorFlow and Keras that I am using\n",
    "print(\"TensorFlow\", tf.__version__)\n",
    "# print(\"Keras\", keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_history(history):\n",
    "  \"\"\"\n",
    "  Visualize the neural network model training history\n",
    "   \n",
    "  :param:history A record of training loss values and metrics values at \n",
    "                 successive epochs, as well as validation loss values \n",
    "                 and validation metrics values\n",
    "  \"\"\"\n",
    "  plt.plot(history.history['accuracy'])\n",
    "  plt.plot(history.history['val_accuracy'])\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transfer(n_classes, freeze_layers=True):\n",
    "  \"\"\"\n",
    "  Use the InceptionV3 neural network architecture to perform transfer learning.\n",
    "     \n",
    "  :param:n_classes Number of classes\n",
    "  :param:freeze_layers If True, the network's parameters don't change.\n",
    "  :return The best neural network\n",
    "  \"\"\"\n",
    "  print(\"Loading Inception V3...\")\n",
    " \n",
    "  # To understand what the parameters mean, do a Google search 'inceptionv3 keras'. \n",
    "  # The first search result should send you to the Keras website, which has an \n",
    "  # explanation of what each of these parameters mean.\n",
    "  # input_top means we are removing the top part of the Inception model, which is the \n",
    "  # classifier. \n",
    "  # input_shape needs to have 3 channels, and needs to be at least 75x75 for the\n",
    "  # resolution.\n",
    "  # Our neural network will build off of the Inception V3 model (trained on the ImageNet\n",
    "  # data set).\n",
    "  base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    " \n",
    "  print(\"Inception V3 has finished loading.\")\n",
    " \n",
    "  # Display the base network architecture\n",
    "  print('Layers: ', len(base_model.layers))\n",
    "  print(\"Shape:\", base_model.output_shape[1:])\n",
    "  print(\"Shape:\", base_model.output_shape)\n",
    "  print(\"Shape:\", base_model.outputs)\n",
    "  base_model.summary()\n",
    " \n",
    "  # Create the neural network. This network uses the Sequential\n",
    "  # architecture where each layer has one \n",
    "  # input tensor (e.g. vector, matrix, etc.) and one output tensor \n",
    "  top_model = Sequential()\n",
    " \n",
    "  # Our classifier model will build on top of the base model\n",
    "  top_model.add(base_model)\n",
    "  top_model.add(GlobalAveragePooling2D())\n",
    "  top_model.add(Dropout(0.5))\n",
    "  top_model.add(Dense(1024, activation='relu'))\n",
    "  top_model.add(BatchNormalization())\n",
    "  top_model.add(Dropout(0.5))\n",
    "  top_model.add(Dense(512, activation='relu'))\n",
    "  top_model.add(Dropout(0.5))\n",
    "  top_model.add(Dense(128, activation='relu'))\n",
    "  top_model.add(Dense(n_classes, activation='softmax'))\n",
    " \n",
    "  # Freeze layers in the model so that they cannot be trained (i.e. the\n",
    "  # parameters in the neural network will not change)\n",
    "  if freeze_layers:\n",
    "    for layer in base_model.layers:\n",
    "      layer.trainable = False\n",
    " \n",
    "  return top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform image augmentation. \n",
    "# Image augmentation enables us to alter the available images\n",
    "# (e.g. rotate, flip, changing the hue, etc.) to generate more images that our\n",
    "# neural network can use for training...therefore preventing us from having to\n",
    "# collect more external images.\n",
    "datagen = ImageDataGenerator(rotation_range=5, width_shift_range=[-10, -5, -2, 0, 2, 5, 10],\n",
    "                             zoom_range=[0.7, 1.5], height_shift_range=[-10, -5, -2, 0, 2, 5, 10],\n",
    "                             horizontal_flip=True)\n",
    " \n",
    "shape = (299, 299)\n",
    " \n",
    "# Load the cropped traffic light images from the appropriate directory\n",
    "img_0_green = object_detection.load_rgb_images(\"traffic_light_dataset/0_green/*\", shape)\n",
    "img_1_yellow = object_detection.load_rgb_images(\"traffic_light_dataset/1_yellow/*\", shape)\n",
    "img_2_red = object_detection.load_rgb_images(\"traffic_light_dataset/2_red/*\", shape)\n",
    "img_3_not_traffic_light = object_detection.load_rgb_images(\"traffic_light_dataset/3_not/*\", shape)\n",
    " \n",
    "# Create a list of the labels that is the same length as the number of images in each\n",
    "# category\n",
    "# 0 = green\n",
    "# 1 = yellow\n",
    "# 2 = red\n",
    "# 3 = not a traffic light\n",
    "labels = [0] * len(img_0_green)\n",
    "labels.extend([1] * len(img_1_yellow))\n",
    "labels.extend([2] * len(img_2_red))\n",
    "labels.extend([3] * len(img_3_not_traffic_light))\n",
    " \n",
    "# Create NumPy array\n",
    "labels_np = np.ndarray(shape=(len(labels), 4))\n",
    "images_np = np.ndarray(shape=(len(labels), shape[0], shape[1], 3))\n",
    " \n",
    "# Create a list of all the images in the traffic lights data set\n",
    "img_all = []\n",
    "img_all.extend(img_0_green)\n",
    "img_all.extend(img_1_yellow)\n",
    "img_all.extend(img_2_red)\n",
    "img_all.extend(img_3_not_traffic_light)\n",
    " \n",
    "# Make sure we have the same number of images as we have labels\n",
    "assert len(img_all) == len(labels)  \n",
    " \n",
    "# Shuffle the images\n",
    "img_all = [preprocess_input(img) for img in img_all]\n",
    "(img_all, labels) = object_detection.double_shuffle(img_all, labels)\n",
    " \n",
    "# Store images and labels in a NumPy array\n",
    "for idx in range(len(labels)):\n",
    "  images_np[idx] = img_all[idx]\n",
    "  labels_np[idx] = labels[idx]\n",
    "     \n",
    "print(\"Images: \", len(img_all))\n",
    "print(\"Labels: \", len(labels))\n",
    " \n",
    "# Perform one-hot encoding\n",
    "for idx in range(len(labels_np)):\n",
    "  # We have four integer labels, representing the different colors of the \n",
    "  # traffic lights.\n",
    "  labels_np[idx] = np.array(to_categorical(labels[idx], 4))\n",
    "     \n",
    "# Split the data set into a training set and a validation set\n",
    "# The training set is the portion of the data set that is used to \n",
    "#   determine the parameters (e.g. weights) of the neural network.\n",
    "# The validation set is the portion of the data set used to\n",
    "#   fine tune the model-specific parameters (i.e. hyperparameters) that are \n",
    "#   fixed before you train and test your neural network on the data. The \n",
    "#   validation set helps us select the final model (e.g. learning rate, \n",
    "#   number of hidden layers, number of hidden units, activation functions, \n",
    "#   number of epochs, etc.\n",
    "# In this case, 80% of the data set becomes training data, and 20% of the\n",
    "# data set becomes validation data.\n",
    "idx_split = int(len(labels_np) * 0.8)\n",
    "x_train = images_np[0:idx_split]\n",
    "x_valid = images_np[idx_split:]\n",
    "y_train = labels_np[0:idx_split]\n",
    "y_valid = labels_np[idx_split:]\n",
    " \n",
    "# Store a count of the number of traffic lights of each color\n",
    "cnt = collections.Counter(labels)\n",
    "print('Labels:', cnt)\n",
    "n = len(labels)\n",
    "print('0:', cnt[0])\n",
    "print('1:', cnt[1])\n",
    "print('2:', cnt[2])\n",
    "print('3:', cnt[3])\n",
    " \n",
    "# Calculate the weighting of each traffic light class\n",
    "class_weight = {0: n / cnt[0], 1: n / cnt[1], 2: n / cnt[2], 3: n / cnt[3]}\n",
    "print('Class weight:', class_weight)\n",
    " \n",
    "# Save the best model as traffic.h5\n",
    "checkpoint = ModelCheckpoint(\"traffic.h5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(min_delta=0.0005, patience=15, verbose=1)\n",
    " \n",
    "# Generate model using transfer learning\n",
    "model = Transfer(n_classes=4, freeze_layers=True)\n",
    " \n",
    "# Display a summary of the neural network model\n",
    "model.summary()\n",
    " \n",
    "# Generate a batch of randomly transformed images \n",
    "it_train = datagen.flow(x_train, y_train, batch_size=32)\n",
    " \n",
    "# Configure the model parameters for training\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adadelta(\n",
    "  lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0), metrics=['accuracy'])\n",
    " \n",
    "# Train the model on the image batches for a fixed number of epochs\n",
    "# Store a record of the error on the training data set and metrics values\n",
    "#   in the history object.\n",
    "history_object = model.fit(it_train, epochs=250, validation_data=(\n",
    "  x_valid, y_valid), shuffle=True, callbacks=[\n",
    "  checkpoint, early_stopping], class_weight=class_weight)\n",
    " \n",
    "# Display the training history\n",
    "show_history(history_object)\n",
    " \n",
    "# Get the loss value and metrics values on the validation data set\n",
    "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])\n",
    " \n",
    "print('Saving the validation data set...')\n",
    " \n",
    "print('Length of the validation data set:', len(x_valid))\n",
    " \n",
    "# Go through the validation data set, and see how the model did on each image\n",
    "for idx in range(len(x_valid)):\n",
    " \n",
    "  # Make the image a NumPy array\n",
    "  img_as_ar = np.array([x_valid[idx]])\n",
    " \n",
    "  # Generate predictions    \n",
    "  prediction = model.predict(img_as_ar)\n",
    " \n",
    "  # Determine what the label is based on the highest probability\n",
    "  label = np.argmax(prediction)\n",
    " \n",
    "  # Create the name of the directory and the file for the validation data set\n",
    "  # After each run, delete this out_valid/ directory so that old files are not\n",
    "  # hanging around in there.\n",
    "  file_name = str(idx) + \"_\" + str(label) + \"_\" + str(np.argmax(str(y_valid[idx]))) + \".jpg\"\n",
    "  img = img_as_ar[0]\n",
    " \n",
    "  # Reverse the image preprocessing process\n",
    "  img = object_detection.reverse_preprocess_inception(img)\n",
    " \n",
    "  # Save the image file\n",
    "  cv2.imwrite(file_name, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    " \n",
    "print('The validation data set has been saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
