{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import object_detection\n",
    "from tensorflow import keras\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the video file is in the same directory as your code\n",
    "filename = 'las_vegas.mp4'\n",
    "file_size = (1920,1080) # Assumes 1920x1080 mp4\n",
    "scale_ratio = 1 # Option to scale to fraction of original size. \n",
    " \n",
    "# We want to save the output to a video file\n",
    "output_filename = 'las_vegas_annotated.mp4'\n",
    "output_frames_per_second = 20.0\n",
    " \n",
    "# Load the SSD neural network that is trained on the COCO data set\n",
    "model_ssd = object_detection.load_ssd_coco()\n",
    " \n",
    "# Load the trained neural network\n",
    "model_traffic_lights_nn = keras.models.load_model(\"traffic.h5\")\n",
    " \n",
    "def main():\n",
    " \n",
    "  # Load a video\n",
    "  cap = cv2.VideoCapture(filename)\n",
    " \n",
    "  # Create a VideoWriter object so we can save the video output\n",
    "  fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "  result = cv2.VideoWriter(output_filename,  \n",
    "                           fourcc, \n",
    "                           output_frames_per_second, \n",
    "                           file_size) \n",
    "     \n",
    "  # Process the video\n",
    "  while cap.isOpened():\n",
    "         \n",
    "    # Capture one frame at a time\n",
    "    success, frame = cap.read() \n",
    "         \n",
    "    # Do we have a video frame? If true, proceed.\n",
    "    if success:\n",
    "         \n",
    "      # Resize the frame\n",
    "      width = int(frame.shape[1] * scale_ratio)\n",
    "      height = int(frame.shape[0] * scale_ratio)\n",
    "      frame = cv2.resize(frame, (width, height))\n",
    "             \n",
    "      # Store the original frame\n",
    "      original_frame = frame.copy()\n",
    " \n",
    "      output_frame = object_detection.perform_object_detection_video(\n",
    "        model_ssd, frame, model_traffic_lights=model_traffic_lights_nn)\n",
    " \n",
    "      # Write the frame to the output video file\n",
    "      result.write(output_frame)\n",
    "             \n",
    "    # No more video frames left\n",
    "    else:\n",
    "      break\n",
    "             \n",
    "  # Stop when the video is finished\n",
    "  cap.release()\n",
    "     \n",
    "  # Release the video recording\n",
    "  result.release()\n",
    "     \n",
    "  # Close all windows\n",
    "  cv2.destroyAllWindows() \n",
    "     \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6628aac0378a00797c729f5a8d51d36d7263e4df468201e41567f7dd339f02e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
