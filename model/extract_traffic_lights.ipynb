{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import import_ipynb\n",
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of jpeg image files containing traffic lights\n",
    "files = object_detection.get_files('traffic_light_input/*.jpg')\n",
    " \n",
    "# Load the object detection model\n",
    "this_model = object_detection.load_ssd_coco()\n",
    " \n",
    "# Keep track of the number of traffic lights found\n",
    "traffic_light_count = 0\n",
    " \n",
    "# Keep track of the number of image files that were processed\n",
    "file_count = 0\n",
    " \n",
    "# Display a count of the number of images we need to process\n",
    "print(\"Number of Images:\", len(files))\n",
    " \n",
    "# Go through each image file, one at a time\n",
    "for file in files:\n",
    " \n",
    "  # Detect objects in the image\n",
    "  # img_rgb is the original image in RGB format\n",
    "  # out is a dictionary containing the results of object detection\n",
    "  # file_name is the name of the file\n",
    "  (img_rgb, out, file_name) = object_detection.perform_object_detection(model=this_model, file_name=file, save_annotated=None, model_traffic_lights=None)\n",
    "     \n",
    "  # Every 10 files that are processed\n",
    "  if (file_count % 10) == 0:\n",
    " \n",
    "    # Display a count of the number of files that have been processed\n",
    "    print(\"Images processed:\", file_count)\n",
    " \n",
    "    # Display the total number of traffic lights that have been identified so far\n",
    "    print(\"Number of Traffic lights identified: \", traffic_light_count)\n",
    "         \n",
    "  # Increment the number of files by 1\n",
    "  file_count = file_count + 1\n",
    " \n",
    "  # For each traffic light (i.e. bounding box) that was detected\n",
    "  for idx in range(len(out['boxes'])):\n",
    " \n",
    "    # Extract the type of object that was detected  \n",
    "    obj_class = out[\"detection_classes\"][idx]\n",
    "         \n",
    "    # If the object that was detected is a traffic light\n",
    "    if obj_class == object_detection.LABEL_TRAFFIC_LIGHT:\n",
    "         \n",
    "      # Extract the coordinates of the bounding box\n",
    "      box = out[\"boxes\"][idx]\n",
    "             \n",
    "      # Extract (i.e. crop) the traffic light from the image     \n",
    "      traffic_light = img_rgb[box[\"y\"]:box[\"y2\"], box[\"x\"]:box[\"x2\"]]\n",
    "             \n",
    "      # Convert the traffic light from RGB format into BGR format\n",
    "      traffic_light = cv2.cvtColor(traffic_light, cv2.COLOR_RGB2BGR)\n",
    " \n",
    "      # Store the cropped image in a folder named 'traffic_light_cropped'     \n",
    "      cv2.imwrite(\"traffic_light_cropped/\" + str(traffic_light_count) + \".jpg\", traffic_light)\n",
    "             \n",
    "      # Increment the number of traffic lights by 1\n",
    "      traffic_light_count = traffic_light_count + 1\n",
    " \n",
    "# Display the total number of traffic lights identified\n",
    "print(\"Number of Traffic lights identified:\", traffic_light_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6628aac0378a00797c729f5a8d51d36d7263e4df468201e41567f7dd339f02e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
